\renewcommand{\documentname}{Theoretical Aspects}

\chapter{Theoretical aspects}\label{theory}

A digital magazine Bootaku works with three freelancers. Dante, Virgil and Beatrice. Together they write a section about book reviews. Gathering data from previous sections, Bootaku wants to define and solve a problem of efficiently assign all reviews to the three critics so that the section gets the highest profit. For the assignments, Bootaku wants every book review to have one (and only one) associated freelancer. If a freelancer ends up with no reviews, the assignments are still valid if and only if the previous condition is met.


\section{Assignment problem}

The problem described before is an example of an assignment problem. It can be generalised with the following elements: 

\begin{description}
    \item A set of $n$ freelancers $f$
    \item A set of $m$ book reviews $r$
    \item An assignment matrix of $n \times m$ assignments $a_{fr}$ such that $a_{fr} = 0$ when freelancer $f$ is not assigned to book review $r$ and $a_{fr} = 1$ when freelancer $f$ is assigned to book review $r$.
    \item A profit matrix of $n \times m$ profits $p_{fr}$ which indicate the profit obtained when assigning freelancer $f$ to book review $r$ and that $p_{fr} \textgreater 0$.
    \item A valid solution is defined as a matrix of assignments where all the book reviews have a freelancer assigned to them and no book review has more than one associated freelancer.
\end{description}

The profit for all the assignments will then be:

\begin{equation}
    \scalebox{2}{$\sum_{f=1}^n \sum_{r=1}^m a_{fr} p_{fr}$}
\end{equation}

The optimal solution consists on having a set of assignments such that the sum of all the profits for the current assignments is maximised.

For example, imagine that for the next month's section, we have the following data. The information is represented by means of two sets: $F$ for the freelancers and $R$ for the reviews.

\begin{align}
    F &= \{ Dante, Virgil, Beatrice \} \\
    R &= \{ {Divina\ Commedia}, {El\ Quijote}, {Voyage\ au\ bout\ de\ la\ nuit}, {Todo\ modo} \}
\end{align}

Then, our assignments and profits will be represented by the $A$ and $P$ matrices.

\begin{equation}
    A = \bordermatrix{
        & DC & EQ & VN & TM \cr
        Dante & a_{11} & a_{12} & a_{13} & a_{14} \cr
        Virgil & a_{21} & a_{22} & a_{23} & a_{24} \cr
        Beatrice & a_{31} & a_{32} & a_{33} & a_{34} 
    } \qquad
\end{equation}

\begin{equation}
    P = \bordermatrix{
        & DC & EQ & VN & TM \cr
        Dante & p_{11} & p_{12} & p_{13} & p_{14}\cr 
        Virgil & p_{21} & p_{22} & p_{23} & p_{24}\cr 
        Beatrice & p_{31} & p_{32} & p_{33} & p_{34} 
    } \qquad
\end{equation}

Where each row represents a freelancer and each column represents a book review. So freelancer 1 is Dante, 2 is Virgil and 3 is Beatrice. The same goes for the book reviews. Book review 1 is \textit{Divina Commedia}, 2 is \textit{El Quijote}, 3 is \textit{Voyage Au Bout De La Nuit} and 4 is \textit{Todo Modo}.

Now, we are going to study valid and non-valid solutions. As we explained before, a solution is valid if every book review has a freelancer assigned to it, and no more than one.

We will analyse four sets of values for the A matrix:

\begin{align}
    A1 &= 
    \begin{bmatrix}
        1 & 0 & 0 & 0\\ 
        0 & 0 & 1 & 0\\ 
        0 & 1 & 0 & 1
    \end{bmatrix} \\
    A2 &= 
    \begin{bmatrix}
        0 & 0 & 0 & 0\\ 
        1 & 0 & 1 & 0\\ 
        0 & 1 & 0 & 1 
    \end{bmatrix} \\
    A3 &= 
    \begin{bmatrix}
        0 & 0 & 1 & 0\\ 
        0 & 0 & 0 & 1\\ 
        1 & 0 & 0 & 0 
    \end{bmatrix} \\
    A4 &= 
    \begin{bmatrix}
        0 & 1 & 1 & 0\\ 
        0 & 0 & 0 & 1\\ 
        1 & 1 & 0 & 0 
    \end{bmatrix}
\end{align}

From these matrices, we can deduce that $A1$ and $A2$ are valid solutions, because they have one freelancer for each book review. We are not concerned with a freelancer having no book reviews assigned. However, a book review without an associated freelancer represents a non-valid solution. That is precisely the case for $A3$, the book review for \textit{El Quijote} has not an assigned freelancer. In the case of $A4$, the fact that \textit{El Quijote} has two freelancers assigned makes it a non-valid solution.

Now, we will give values to the $P$ matrix in order to discuss possible optimal solutions. We will compare them with the assignment matrices $A1$ and $A2$

\begin{align}
    P1 &= 
    \begin{bmatrix}
        9 & 1 & 5 & 4\\ 
        2 & 8 & 14 & 2\\ 
        7 & 11 & 10 & 6
    \end{bmatrix} \\
    P2 &= 
    \begin{bmatrix}
        9 & 1 & 5 & 4\\ 
        13 & 8 & 14 & 2\\ 
        7 & 11 & 10 & 6
    \end{bmatrix}
\end{align}

$P1$ and $A1$:

\begin{equation}
    \scalebox{1.2}{$Profit = \sum_{f=1}^n \sum_{r=1}^m a_{fr} p_{fr} = 9 + 11 + 14 + 6 = 40$}
\end{equation}

$P1$ and $A2$:

\begin{equation}
    \scalebox{1.2}{$Profit = \sum_{f=1}^n \sum_{r=1}^m a_{fr} p_{fr} = 2 + 11 + 14 + 6 = 33$}
\end{equation}

We can observe that for $P1$, the assignments defined in $A1$ are better than those in $A2$, because they result in a better profit. Another important remark about $A1$ is that it is the optimal solution to the problem, because it assigns the book reviews to the freelancers with the best profit value for their assigned books. Now $P2$ will be evaluated.

$P2$ and $A1$:

\begin{equation}
    \scalebox{1.2}{$Profit = \sum_{f=1}^n \sum_{r=1}^m a_{fr} p_{fr} = 9 + 11 + 14 + 6  = 40$}
\end{equation}

$P2$ and $A2$:

\begin{equation}
    \scalebox{1.2}{$Profit = \sum_{f=1}^n \sum_{r=1}^m a_{fr} p_{fr} = 13 + 11 + 14 + 6 = 44$}
\end{equation}

In the case of the profits values of $P2$, the situation is reversed. $A2$ is now the optimal solution and therefore better than $A1$.

The important thing to notice here is that the values for the $P$ matrix right now may appear as having no meaning whatsoever. But we need to think of $P$ as the results obtained from a profit funtion. Then, we can interpret $P1$ as values of profit in a context where Virgil has just expressed an opinion on social media about the \textit{Divina Commedia} and caused a massive controversy. We can then say that $P1$ is a function which gives more importance to public relations and so the profit $p_{21}$ is very low, whereas $P2$ gives more importance to views and so the profit $p_{21}$ is higher. Of course, in a real problem you know what the function is calculating, but this shows how we can add meaning to a set of symbols in order to understand the data more efficiently.

With this, we have discussed an assignment problem, looked at its main components and analysed its non-valid, valid and optimal solutions. Some final remarks about the relation between a general assignment problem and the Bootaku problem follow. The actors that perform the jobs, in this case the freelancers that \textit{write} the reviews, are called the \textit{agents}. The \textit{tasks} to be performed are, in the Bootaku problem, the book reviews. Nevertheless, the agents in an assignment problem do not need to be persons (or even things that carry out actions), they can be machines, warehouses, or classrooms. The same can be said for the tasks.


\section{Greedy algorithms}

One way of solving the Bootaku problem described earlier can be found in \textit{greedy algorithms}. A greedy algorithm \cite{guerequetavallecillo98algdesign} will try to find a subset of candidates that meet the problem constraints and that form the optimal solution. To do so, the algoritm is run iteratively. In each iteration, it will select the best candidate for that precise moment, neglecting future consequences (that is why they are called \textit{greedy})\footnote{For example, let's say I'm walking down the street and I get thirsty. On my mental list of candidate drinks, water has a value of 5 points, lemonade 3 and tea 1. The first vending machine I come across on the street only sells lemonade and tea, so I buy lemonade. However, on the next street I find another vending machine that sells water, but as I am no longer thirsty I don't buy any more drinks. That is, I found a valid solution but not the optimal solution.}. Before adding a candidate to the solution, the algorithm will determine if it is promising. If the answer is yes, then the candidate is added to the solution. Otherwise, the candidate is no longer evaluated. Each time a candidate is added to the solution, the greedy checks whether the current solution is valid or not.

With this in mind, here follows the \textit{pseudocode} of the generic Greedy Algorithm.

\begin{algorithm}[H]
    \caption{Generic Greedy Algorithm}
    \begin{algorithmic}[1]
        \Procedure {GreedyAlgorithm}{candidates}
            \State {$x \gets \epsilon$} 
            \State {$solution\gets \{\}$}
            \State {$found\gets false$}
            \While {$\ !isEmpty(candidates)\ \text{ and } !found$}
                \State {$x\gets selectCandidate(candidates)$}
                \If {$\ isPromising(x,\ candidates)$}
                    \State {$addToSolution(x,\ solution)$}
                    \If {$\ isSolution(solution)$}
                        \State {$found\gets true$}
                    \EndIf
                \EndIf
            \EndWhile
            \State \textbf{return} $solution$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

As we can see, the generic greedy algorithm has a very simple and elegant definition. However, even though greedy algorithms are easy to implement and can obtain efficient solutions, they are not perfect. Their main flaw relies on their  selection function. It is difficult to design a function that can simultaneously find a good local result and translate it into a good global result. That is, the best candidate in some iteration may not be part of the optimal solution. 

Next, we will solve the Bootaku problem using a greedy algorithm. The greedy algorithm that we are going to use is inspired by the one defined in \cite{guerequetavallecillo98algdesign} for solving the \textit{Assignment of tasks} problem.

\begin{algorithm}[H]
    \caption{Greedy Algorithm for the Bootaku problem}
    \begin{algorithmic}[1]
        \Procedure {GreedyBootaku}{profits, assignments}
            \State {$best \gets \epsilon$}
            \For {$\ \text{each freelancer } F_{i} \in F$}
                \For {$\ \text{each review } R_{j} \in R$}
                    \State {$assignments[F_{i},\ R_{j}] = false$} \Comment{We initialise the assignments matrix (to false or cero, it does not matter).}
                \EndFor
            \EndFor
            \For {$\ \text{each review } R_{j} \in R$}
                \State {$best \gets bestFreelancerFor(profits,\ assignments,\ R_{j})$}
                \State {$assignments[best,\ R_{j}] = true$} \Comment{Again, it can be true or one, depending on the implementation.}
            \EndFor
            \State \textbf{return} $assignments$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
    \caption{bestFreelancerFor procedure for the Bootaku problem}
    \begin{algorithmic}[1]
        \Procedure {bestFreelancerFor}{profits, assignments, review}
            \State {$best \gets \epsilon$} 
            \State {$min\gets \text{maximum integer value}$}
            \For {$\ \text{each freelancer } F_{i} \in F$}
                \If {$\ profits[F_{i},\ review] < min$}
                    \State {$min \gets profits[F_{i},\ review]$}
                    \State {$best \gets F_{i}$}
                \EndIf
            \EndFor
            \State \textbf{return} $best$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

Those are the two procedures needed in order to solve the Bootaku problem. In the \textit{Assignments of tasks} problem described in the book, the authors define an extra function that checks if the worker is already assigned to another task. However, because our problem is not balanced (we have a different number of tasks and agents), it means that we can have a freelancer writing more than one book review, so that extra function is not required.

The Bootaku problem is really simple to solve because of its lack of constraints. This is done deliberately to focus more on the components of assignment problems and to not waste time on explaining difficult restrictions. However, most problems, including the real problem this document defines (to assign classrooms to the groups of the School), have a lot of constraints. 

One way to complicate the Bootaku problem would be to assign completion times to each review. We would have a $n \times m$ $T$ matrix with the completion times for all freelancers and reviews.

\begin{equation}
    T = \bordermatrix{
        & DC & EQ & VN & TM \cr
        Dante & t_{11} & t_{12} & t_{13} & t_{14} \cr
        Virgil & t_{21} & t_{22} & t_{23} & t_{24} \cr
        Beatrice & t_{31} & t_{32} & t_{33} & t_{34} 
    } \qquad
\end{equation}

Then we could have a maximum time per freelancer. This would force the greedy algorithm to perform a check before assigning a review to a freelancer. If the time it takes to write the review surpases the maximum time available for that freelancer, the assignment cannot be made. 

Let's say that Beatrice has been assigned to the book review for \textit{El Quijote}, so she has already spent a total time of $t_{32} \leq maxTime$. In a future iteration the greedy algorithm evaluates Beatrice for reviewing \textit{Todo Modo}. Even if she has the greatest profit for \textit{Todo modo}, it is still not enough. The greedy algorithm first has to check in the $bestFreelancerFor$ procedure if $t_{32} + t_{34} \leq maxTime$ and, if the condition is true, then the assignment is performed. 

We can notice in the Beatrice example the main failure of greedy algorithms. She was assigned to \textit{El Quijote} for a profit $p_{32}$ and then evaluated again for \textit{Todo modo} with a profit $p_{34}$. Imagine that she has not enough time left to be able to review the second book and that $p_{34}$ is \textit{way bigger} than $p_{32}$. This is where assigning the best local result $a_{32}$ would end up ruling out the possibility of assigning the better global result $a_{34}$.



\section{Heuristics and metaheuristics}

Search strategies in a search problem can be \textit{informed} or \textit{uninformed}. Informed strategies use knowledge specific to a given problem but that is outside of its definition, making this type of strategies more efficient than uninformed strategies. The main way of applying our knowledge of a given problem into the search algorithm designed to solve said problem is by means of \textit{heuristic functions}. An heuristic function $h(n)$ \cite{russellnorvig10ai} represents an estimation of the minimum cost of getting to the objective state from the state given by node $n$. To expand a node, the algorithm also makes use of an \textit{evaluation function}. An evaluation function $f(n)$ analyses the non-expanded nodes and selects the one with the lowest cost. In the case of greedy algorithms, the evaluation function of a node n is equivalent to the heuristic function of the same node. So we have that $f(n) = h(n)$.

Now that we have explained what heuristic functions are, one question remains. What are \textit{metaheuristics}? Analysing the word, one could think that the \textit{meta} prefix implies that metaheuristics are \textit{heuristics about heuristics}, in the same way \textit{metadata} is \textit{data about data}. However, as Luke \cite{luke13metaheuristics} points out, this is not the case at all. He defines metaheuristics as:

\begin{displayquote}
    ... a rather unfortunate term often used to describe a major subfield, indeed the primary subfield, of \textbf{stochastic optimization}. Stochastic optimization is the general class of algorithms and techniques which employ some degree of randomness to find optimal (or as optimal as possible) solutions to hard problems. Metaheuristics are the most general of these kinds of algorithms, and are applied to a very wide range of problems.
\end{displayquote}

There are many methods of designing algorithms based on \textit{metaheuristics}. In this project we will focus on the Evolutionary Computation method, a subtype of Population-based methods.


\subsection{Evolutionary Computation}

Evolutionary Computation (EC) \cite{luke13metaheuristics} takes inspiration from population biology, genetics and evolution \footnote{Because this method uses vocabulary from these fields of biology, we have followed Luke's approach and defined these terms one by one. A list of definitions of the most commonly used terms in EC has been created in the annex of definitions and abbreviations.}. We are interested in the types of algorithms designed using this method, known as Evolutionary Algorithms (EAs). An EA may be (most of the times) either a \textit{generational algorithm} or a \textit{steady-state algorithm}.  A generational algorithm creates a new population of individuals, based on the previous one, in each iteration. Moreover, a steady-state algorithm changes a subset of individuals in each iteration, but not the entire population. The most common EAs are the \textit{Genetic Algorithms} and the \textit{Evolution Strategies}, and there are generational and steady-state versions of the two.

Below is the pseudocode for an abstract generational algorithm.

\begin{algorithm}[H]
    \caption{Abstract Generational Algorithm}
    \begin{algorithmic}[1]
        \Procedure {AbstractGenerationalAlgorithm}{maxTime}
            \State {$P \gets \text{create the initial population}$} 
            \State {$best\gets \epsilon$}
            \State {$currentTime\gets \text{get current time}$}
            \While {$\ !idealSolution(P)\ \text{ and } currentTime \leq maxTime$}
                \State {$evaluate(P)$}\Comment{Calculate the fitness of all individuals.}
                \For {$\ \text{each individual } P_{i} \in P$}
                    \If {$\ best = \epsilon \text{ and } Fitness(P_{i}) > Fitness(best)$}
                        \State {$best\gets P_{i}$}
                    \EndIf
                \EndFor
                \State {$P\gets newGeneration(P,\ breed(P))$}
                \State {$currentTime\gets \text{update time}$}
            \EndWhile
            \State \textbf{return} $best$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

The initial population in this kinds of algorithms is created by adding random individuals to a set until the maximum population size is reached. Some good practices for this process follow. The most important thing is not generating repeated individuals. This can be done with a dictionary in which we store the individuals as keys. For every new randomly generated individual we check if it is not already contained in said dictionary before adding it to the population set. Finally, it is possible to include individuals designed by hand into the initial population (this is called \textit{seeding} the population). However, the use of EAs already implies that finding a good heuristic for the problem is not trivial. So even if we think that the individuals we design may be going in the right direction, it is very likely that they will end up producing poor results.

The main difference between generational EAs relies on how they create the new generation. This process is done by means of different operations such as \textit{selection}, \textit{crossover} and \textit{mutation}. Also, some EAs simply discard all the parents in the new generation and others include them again if they have an acceptable fitness. We will take a look at two specific EAs in the following sections, Evolution Strategies and Genetic Algorithms.


\subsection{Evolution Strategies}

Evolution Strategies (ES) \cite{luke13metaheuristics} are a type of Evolutionary Algorithms. They make use of a selection operator called \textit{Truncation Selection}. This operator consists of selecting individuals from the highest to the lowest fitness value until a predetermined number of selected candidates is reached. For creating the new generation, ES simply use the mutation operator, without combining it with a crossover operator.

The only ES to be covered in this section is the $(\mu,\ \lambda)$ algorithm. We have chosen it because it is one of the simplest ES and therefore easier to understand. The design of $(\mu,\ \lambda)$ is essentially one version of the Abstract Generational Algorithm that details the way in which the new generation is built. This new generation is constructed by using both $\mu$ and $\lambda$ parameters.

In this algorithm, we have an initial population of $\lambda$ number of individuals which are randomly generated. Then, we evaluate the fitness of all individuals, as we did in the Abstract Generational Algorithm, and we calculate the best individual in the generation. The next step is to create the new generation. To do so, $(\mu,\ \lambda)$ performs the Truncation Selection on the parents, selecting the $\mu$ number of parents with greatest fitness, and for each parent a $\lambda / \mu$ number of children are generated. A mutation operation is performed to create the offspring from a copy of their parent. This whole process is done until we arrive at an optimal solution or the maximum time runs out. The pseudocode of the $(\mu,\ \lambda)$ algorithm is shown as follows.

\begin{algorithm}[H]
    \caption{The $(\mu,\ \lambda)$ Evolution Strategy}
    \begin{algorithmic}[1]
        \Procedure {MuLambdaES}{$\mu$, $\lambda$}
            \State {$best\gets \epsilon$}
            \State {$P \gets \{ \}$} 
            \For {$\ \lambda \text{ times}$}
                \State {$P\gets P \cup \{ \text{new random individual} \}$}
            \EndFor
            \While {$\ !idealSolution(P)\ \text{ and } currentTime \leq maxTime$}
                \State {$evaluate(P)$}\Comment{Calculate the fitness of all individuals.}
                \For {$\ \text{each individual } P_{i} \in P$}
                    \If {$\ best = \epsilon \text{ and } Fitness(P_{i}) > Fitness(best)$}
                        \State {$best\gets P_{i}$}
                    \EndIf
                \EndFor
                \State {$Q\gets \mu \text{ individuals with the highest to lowest fitness}$}
                \State {$P \gets \{ \}$} 
                \For {$\ \text{each individual } Q_{j} \in Q$}
                    \For {$\ \lambda / \mu \text{ times}$}
                        \State {$P\gets P \cup \{ mutation(copy(Q_{j})) \}$}
                    \EndFor
                \EndFor
                \State {$currentTime\gets \text{update time}$}
            \EndWhile
            \State \textbf{return} $best$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

Knowing how to give values to the parameters $\lambda$, $\mu$ and the mutation probability is very important in this algorithm. In the case of $\lambda$, as it approaches $\infty$ the algorithm starts behaving as a random search algorithm, so it is best if it does not have an excessively high value. For $\mu$, if we give it a very low value, the algorithm becomes very selective and focuses only of a specific type of individual with a high fitness value. This may result in \textit{premature convergence} of the algorithm and thus end the execution with a locally optimal rather than a globally optimal solution. Lastly, because the mutation operation determines the similarity between parents and offsprings, if the mutation probability is very high, the new population would be very different from the previous one. Therefore, it would make children appear like random individuals.

To conclude the section, simply note that there is another algorithm, very similar to this one, called $(\mu + \lambda)$. The only difference between $(\mu + \lambda)$ and $(\mu,\ \lambda)$ is that while $(\mu,\ \lambda)$ discards the parents when creating the new generation, $(\mu + \lambda)$ makes a union between parents and children. This makes each new generation of the $(\mu + \lambda)$ algorithm having a size of $\mu + \lambda$, where $\mu$ is the number of parents and $\lambda$ the number of new offspring. Because very fit parents can survive for several generations, $(\mu + \lambda)$ behaves like a $(\mu,\ \lambda)$ with a very low $\mu$ number, it can terminate with a premature convergence.


\subsection{Genetic algorithms}

The Genetic Algorithm (GA) \cite{luke13metaheuristics} is a type of Evolutionary Algorithms with a strong similarity towards the $(\mu,\ \lambda)$ Evolution Stategy. What separates the two algorithms the most is the selection operation and the way a new generation is created. In $(\mu,\ \lambda)$, candidates were chosen by Truncated Selection. Once the candidates are selected, the next generation is populated by mutations of the parental copies. However, in the GA, a pair of parents is selected and their offspring are immediately created, adding them to the new generation. This process of simultaneous selection and reproduction occurs until the population reaches the maximum number of individuals set. Further discussion of the GA will follow, once we have seen its pseudocode.

\begin{algorithm}[H]
    \caption{The Genetic Algorithm (GA)}
    \begin{algorithmic}[1]
        \Procedure {GeneticAlgorithm}{popsize, maxTime}
            \State {$best\gets \epsilon$}
            \State {$P \gets \{ \}$} 
            \For {$\ popsize \text{ times}$}
                \State {$P\gets P \cup \{ \text{new random individual} \}$}
            \EndFor
            \While {$\ !idealSolution(P)\ \text{ and } currentTime \leq maxTime$}
                \State {$evaluate(P)$}\Comment{Calculate the fitness of all individuals.}
                \For {$\ \text{each individual } P_{i} \in P$}
                    \If {$\ best = \epsilon \text{ and } Fitness(P_{i}) > Fitness(best)$}
                        \State {$best\gets P_{i}$}
                    \EndIf
                \EndFor
                \State {$Q\gets \{ \}$} \Comment{Here the GA begins to differ from $(\mu,\ \lambda)$.}
                \For {$\ popsize / 2 \text{ times}$}
                    \State {$\text{Parent } P_{a} \gets selectWithReplacement(P)$}
                    \State {$\text{Parent } P_{b} \gets selectWithReplacement(P)$}
                    \State {$\text{Children } C_{a}, C_{b} \gets crossover(copy(P_{a}), copy(P_{b}))$}
                    \State {$Q\gets Q \cup \{ mutate(C_{a}), mutate(C_{b}) \}$}
                \EndFor
                \State {$P\gets Q$}
                \State {$currentTime\gets \text{update time}$}
            \EndWhile
            \State \textbf{return} $best$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

As we said before, the GA is differentiated from the $(\mu,\ \lambda)$ ES by means of its selection, crossover and mutation operators. We will now elaborate on these operators, defining them and explaining some of their implementations.

\subsubsection{Selection}

We begin with the selection operator. Even if the selection variant in the GA is different from the one in $(\mu,\ \lambda)$, the concept of selection is equivalent in both algorithms. In other words, both use the operation of selection to obtain the parents who will produce the children of the future generation.. There can be multiple ways to implement the selection operator, including \textit{Random Selection}, \textit{Fitness-Proportionate Selection}, \textit{Stochastic Universal Sampling}, \textit{Tournament Selection} and a variant of the GA which includes \textit{elitism}.

The random selection variant, as its name implies, picks two random parents, removing them from the population. After generating the offspring, another pair of parents is selected and so on, until the new population is complete. In the GA designed to solve the problem of classroom management, we used this variant combined with a tournament between the randomly selected pair of parents and their two generated children to select the best two individuals out of the four (in terms of fitness).

\begin{algorithm}[H]
    \caption{Random Selection}
    \begin{algorithmic}[1]
        \Procedure {RandomSelection}{P}
            \State {$selected \gets \text{random individual from population $P$}$} 
            \State {$remove(selected,\ P)$} \Comment{The individual is removed from the population.}
            \State \textbf{return} $selected$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

Next, we will address the topic of Fitness-Proportionate Selection, also known as \textit{Roulette Selection}. In this variant, all individuals are dimensioned according to their fitness. If we think of this process as a lottery, the larger the size of an individual, i.e. the greater the fitness, the more likely the individual is to win the lottery prize. In this case that prize is to be selected to be a parent. This means that a random number $n$ such that $0 \leq n \leq \text{the total sum of all fitness values}$ will fall in range of one of the individuals, thus selecting such an individual.

\begin{algorithm}[H]
    \caption{Fitness-Proportionate Selection}
    \begin{algorithmic}[1]
        \Procedure {GenerationPreparations}{P}\Comment{Executed only one time at the start of each generation.}
            \State {$\textbf{global}\ \vec{p} \gets \langle p_{1},p_{2},...,p_{l} \rangle$} \Comment{Vector which copies all individuals in P.}
            \State {$\textbf{global}\ \vec{f} \gets  \langle f_{1},f_{2},...,p_{l} \rangle$} \Comment{Vector with the fitness values of all the individuals in $\vec{l}$, keeping the order.}
            \If {$\ \vec{f} \text{ contains only zeros}$}
                \State {Substitute all items of $\vec{f}$ with ones}
            \EndIf
            \For {$\ i \text{ from } 2 \text{ to } l$} \Comment{Convert $\vec{f}$ into a cumulative distribution.}
                \State {$f_{i}\gets f_{i} + f_{i-1}$}
            \EndFor
        \EndProcedure
        \Procedure {FitnessProportionateSelection}{P}
            \State {$n\gets \text{random number from $0$ to $f_{i}$ inclusive}$} 
            \State {$selected \gets p_{1}$}
            \For {$\ i \text{ from } 2 \text{ to } l$}
                \If {$\ f_{i-1} < n \leq f_{i}$}
                    \State {$selected \gets p_{i}$}
                \EndIf
            \EndFor
            \State \textbf{return} $selected$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

We can observe that this operator uses two procedures. The first one is an auxiliary procedure named \textit{GenerationPreparations}, which defines the global vector variables $\vec{p}$ and $\vec{f}$ representing the individuals of the population and their fitness values. The second and main one is the actual selection. In this main procedure we obtain a random number and extract the individual whose range of values contains that chosen random number.

A derivative of the Fitness-Proportionate Selection operator mentioned at the beginning of the section is called Stochastic Universal Sampling (SUS). SUS has two very similar procedures to the ones shown before, one executed one time each generation (normally) that defines some global variables and a main procedure which performs the selection. The main difference comes in how the selection is performed. Let $s$ be the sum of all fitness values and $l$ be the population size. A random number generated between $0$ and $s / l$ will select the individual in that range. For every remaining selection the position value, which started in the random number, is increased by $s / l$ and a new selection is carried out (up to a maximum of $l$ times).

\begin{algorithm}[H]
    \caption{Stochastic Universal Sampling Selection}
    \begin{algorithmic}[1]
        \Procedure {GenerationPreparations}{P}\Comment{Executed only one time at the start of each generation.}
            \State {$\textbf{global}\ \vec{p} \gets \langle p_{1},p_{2},...,p_{l} \rangle$} \Comment{Vector which copies all individuals in P.}
            \State {$\vec{p} \gets shuffle(\vec{p})$}
            \State {$\textbf{global}\ \vec{f} \gets \langle f_{1},f_{2},...,p_{l} \rangle$} \Comment{Vector with the fitness values of all the individuals in $\vec{l}$, keeping the order.}
            \State {$\textbf{global}\ index \gets 0$}
            \If {$\ \vec{f} \text{ contains only zeros}$}
                \State {Substitute all items of $\vec{f}$ with ones}
            \EndIf
            \For {$\ i \text{ from } 2 \text{ to } l$} \Comment{Convert $\vec{f}$ into a cumulative distribution.}
                \State {$f_{i}\gets f_{i} + f_{i-1}$}
            \EndFor
            \State {$\textbf{global}\ value \gets \text{random number from $0$ to $f_{l}/l$ inclusive}$}
        \EndProcedure
        \Procedure {SUS}{P}
            \While {$\ f_{index} < value$}
                \State {$index \gets index + 1$}
            \EndWhile
            \State {$value \gets value + f_{l}/l$}
            \State \textbf{return} $selected$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

The main advantage of Stochastic Universal Sampling over Fitness-Proportionate selection lies in the fact that while an individual with a high fitness (higher than $s/l$) might never be chosen in a Fitness-Proportionate selection, in the Stochastic Universal Sampling variant its selection is guaranteed.

The last variant we will explain is the Tournament Selection. In contrast with these past two variants, the Tournament Selection is a very straightforward algorithm. In it, a $t$ number of candidates are selected and the fittest is returned, like a sports competition. Every time a $t_{i}$ candidate is selected, it is removed from the population. The pseudocode for this variant is shown below. 

\begin{algorithm}[H]
    \caption{Tournament Selection}
    \begin{algorithmic}[1]
        \Procedure {TournamentSelection}{P, t}
            \State {$best \gets \text{random individual from population $P$}$}
            \State {$remove(best,\ P)$}
            \For {$\ i \text{ from } 2 \text{ to } t$}
                \State {$next \gets \text{random individual from population $P$}$}
                \State {$remove(next,\ P)$}
                \If {$\ fitness(next) > fitness(best)$}
                    \State {$best \gets next$}
                \EndIf
            \EndFor
            \State \textbf{return} $best$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

This variant is both simple and flexible. Its flexibily comes from the variable size of candidates for the tournaments. Some considerations for the value of $t$ follow. If $t$ is very low, the operator behaves like a random search. However, if $t$ is very high, the individual with the greatest fitness value will have a much higher likelihood of showing up and getting picked every time. As we stated when talking about Random Selection, a combination of both Random and Tournament selections were implemented in the final design of the GA used in the prototype.


