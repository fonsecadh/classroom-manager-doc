\renewcommand{\documentname}{Proposed solution}

\chapter{Proposed solution}


\section{Search space}


\subsection{Assignments}

An assignment is a tuple which associates a group with a classroom.

\begin{equation}
    \scalebox{1.5}{$(G_{i}, C_{j})$}
\end{equation}

Because a group can only have \textit{one} classroom assigned, an assignment can be identified by the \textit{code} \footnote{The name convention previously mentioned: \textit{subject.type.name} (e.g. Com.T.1).} of the group. For example, the assignment for group SI.T.1 can be identified by the code SI.T.1 as well.

Assigning just \textit{one} classroom to each group means that the total number of assignments is calculated by the following expression.

\begin{equation}
    \scalebox{1.2}{$TotalNumberOfAssignments = \left|G\right|$}
\end{equation}

This implies that there are as many assignments as the number of groups for the semester.

\subsection{Solutions}

A \textit{solution} for this problem is represented by a set of all the assignments must be performed for the semester. As presented in the previous section, the total number of assignments equals the total number of groups in that semester. So we have the next statement.

\begin{equation}
    Solution = \{ (G_{1}, C_{x}), (G_{2}, C_{y}), ..., (G_{m}, C_{z})) \}
\end{equation}

Where $m$ is the total number of groups and $x$, $y$ and $z$ are the index for the classrooms assigned to the groups. Note that the classrooms are not sequential (e.g $x$ could represent $C_{12}$ and $y$ represent $C_{3}$).

An \textit{empty solution} is represented by a set of all the assignments where each assignment is \textit{incomplete}. We mean that an assignment is incomplete when the group has no classroom assigned.

\begin{equation}
    IncompleteAssignment = (G_{i}, -)
\end{equation}

So, for the empty solution, we have a set with the following format.

\begin{equation}
    EmptySolution = \{ (G_{1}, -), (G_{2}, -), ..., (G_{m}, -)) \}
\end{equation}

Finally, a \textit{partial solution} is one in which not every assignment was performed, and a \textit{complete solution} is defined by a set in which all the assignments have been performed and each group has a classroom associated with it.

\subsection{States}

A \textit{state} represents a phase in the problem. There can be three states. The \textit{initial state}, which stands for the empty solution of non allocated assignments. The \textit{final state}, which represents a complete solution with all the assignments performed. And the \textit{intermediate states} portraying partial solutions.

A key concept to understand our solution is the following. Although by default we start the execution of the algorithms with an initial state, it is also possible to start the execution with an intermediate state. This is because we can receive as input a partial or total solution of assignments and work from there. Now we will discuss how we can jump from one state to the next, which is normally called \textit{state expansion}.

To expand a state, one of the non performed assignments in the solution is executed. This means that every time a classroom is assigned to a group the state is being expanded. To perform an assignment, the number of possible candidates is the same as the number of classrooms. So we have the following.

\begin{equation}
    \scalebox{1.2}{$TotalNumberOfCandidates = \left|C\right|$}
\end{equation}

Nevertheless, as there exist constraints that indicate wether or not the solution is valid, there are filters which reduce the number of available classrooms for a group. This allows for optimized and easy to retrieve calculations in the execution of the greedy algorithm (this will be explained later in \ref{classroom-filters}). The important thing to note at this moment is that, because of these filters, not all states can be expanded.

\subsection{Instances}

The complexity of the calculations and completion time depend on many factors. Some of those factors follow. First, the number of groups for the semester, which directly translates to the number of assignments to be made. Second, the number of classrooms. If there are more classrooms, it is easier to avoid collisions. Obviously, the number of groups is much more volatile between semesters than the number of classes, which is likely to change very occasionally, if at all. Lastly, the case of starting the prototype with an intermediate state. This means that the set of assignments represents a partial solution given as input. The number of calculations decreases in direct proportion to the assignments already made, therefore the completion time would be lower.

Because of the constraints of the problem, there are some groups where class allocations are more straightforward. For example, a group with only one positive restriction is either going to have that classroom assigned to it or, if it collides with other group, end up unallocated. This is why all the groups that just have one available classroom are assigned first. Also, the groups which have less students have more available classrooms than those with a large number of members.



\section{Collisions}

A collision is an overlap of the timetable of two different groups. For a collision to occur, the groups must clash at least once in the same week, day and time. Collisions are an essential part of this problem, as we cannot assign a classroom to a group if another group was previously associated with that classroom and both groups collide.

\subsection{Lazy Collision Matrix}\label{lcm}

Due to the large number of assignments that have to be made throughout the execution cycle of the genetic algorithm, the chosen data structures were properly analysed. This is where the \textit{Lazy Collision Matrix} comes in.

Imagine that we have the following group set.

\begin{equation}
    G = \{ G_{1}, G_{2}, G_{3} \}
\end{equation}

Then, our initial Lazy Collision Matrix would be represented by the expression below.

\begin{equation}
    LCM = \bordermatrix{
        & G_{1} & G_{2} & G_{3} \cr
        G_{1} &  & -1 & -1 \cr
        G_{2} & -1 &  & -1 \cr
        G_{3} & -1 & -1 & 
    } \qquad
\end{equation}

First of all, the diagonal is empty because we never compare one group against itself. Then, we can observe that the rest of values are defaulted to $-1$. Why? Because there are \textit{not yet evaluated}. That is the reason behind the name of the matrix. It is \textit{lazy} because the collisions are only calculated when needed.

Continuing with this example, imagine that we assign classroom $C_{x}$ to group $G_{1}$. Then, $G_{2}$ also tries to have $C_{x}$ assigned to it, so we check if both groups collide. We find out that they do, so we update the matrix.

\begin{equation}
    LCM = \bordermatrix{
        & G_{1} & G_{2} & G_{3} \cr
        G_{1} &  & 1 & -1 \cr
        G_{2} & 1 &  & -1 \cr
        G_{3} & -1 & -1 & 
    } \qquad
\end{equation}

Therefore, the values are updated with a $1$, which indicates that both groups \textit{collide}. This results in a different classroom $C_{y}$ being assigned to $G_{2}$. Now, $G_{3}$ has that classroom also available, so we check if it clashes with $G_{2}$. We learn that they do not collide. We update the matrix again.

\begin{equation}
    LCM = \bordermatrix{
        & G_{1} & G_{2} & G_{3} \cr
        G_{1} &  & 1 & -1 \cr
        G_{2} & 1 &  & 0 \cr
        G_{3} & -1 & 0 & 
    } \qquad
\end{equation}

The value for non-collision is $0$, as observed. Because $G_{3}$ does not clash with $G_{2}$, they are both allocated in the same classroom.

We can now generalise the LCM as in the next expression.

\begin{equation}
    LCM = \bordermatrix{
        & G_{1} & G_{2} & G_{3} \cr
        G_{1} &  & g_{12} & g_{13} \cr
        G_{2} & g_{21} &  & g_{23} \cr
        G_{3} & g_{31} & g_{32} & 
    } \qquad
\end{equation}

Where a value $g_{ij}$ can be

\[
    \begin{cases}
        1\text{,} &\quad\text{if $G_{i}$ collides with $G_{j}$}\\
        0\text{,} &\quad\text{if $G_{i}$ does not collide with $G_{j}$}\\
        -1\text{,} &\quad\text{if the collision has not yet been evaluated}\\
        \epsilon\text{,} &\quad\text{otherwise}
    \end{cases}
\]

The main advantage of this design is that we do not have to calculate all collisions. For example, a collision between a laboratory group and a theory group would be pointless to calculate because they would never be allocated in the same classroom. Therefore we alleviate the number of calculations. 

As there is only one Lazy Collision Matrix, all calculations performed by the greedy algorithm across all populations in all generations are stored in just one place. This means that all collisions are being calculated only when necessary and only once. Think of the previous example. In a future iteration the greedy algorithm wants to check if groups $G_{1}$ and $G_{2}$ collide. It access the corresponding location in the LCM, and because it contains a $1$, the greedy concludes that they indeed collide. This is done with a $O(1)$ complexity, as the matrix is coded as a dictionary of dictionaries. If instead the greedy wanted to check if groups $G_{1}$ and $G_{3}$ collided, because the LCM has a $-1$ in that position, the greedy would have to perform the collision check and then update the matrix.



\section{Classroom filters}\label{classroom-filters}

A classroom filter is a function. It receives as input either the $C$ set or a subset $I \subset C$, and outputs a new subset $F \subset C$ with the available classrooms for a given group. It filters out the classrooms that do not comply with the hard constraints for that particular group (except collisions, which are calculated later with the LCM, see \ref{lcm}). All groups have the \textit{same} classroom filters.

For example, let us consider a group $G_{i}$ with type $T_{j}$ and $x$ students. A type filter for $G_{i}$ would remove from the result set all the classrooms with a type different from $T_{j}$. A capacity filter would then take the  set resulting from the previous type filter and use it as input. Then it would eliminate from the set all classrooms with a capacity lower than $x$ and return the new $F$ set.

This reduces the number of classrooms that the greedy has to evaluate and therefore decreases the complexity of the calculations. Furthermore, the filters are deterministic, that is, the execution of the filters of a group will always give the same results. This means that, if needed, the filters are only performed once per group per execution.

This may lead us to this question. \textit{If all classroom filters are executed only once per group every time you run the prototype, why bother using a lazy approach for storing them? Would it not be better to perform and store them in a dictionary at the start of the execution?} The answer is no. It is true that if we start from an empty solution the lazy approach does not present a big advantage. Nonetheless, in the case of partial solutions, it reduces the number of calculations. For example, if we want to assign a classroom to a new group created in the middle of the semester, the only thing we care about is if the group collides with any other group. The filters for the rest of the groups are, in that situation, irrelevant. This is due to the fact that they have already been allocated to their corresponding classrooms.


\subsection{Lazy Filter Dictionary}\label{lfd}

The filters work in a similar way to the Lazy Collision Matrix. Again, the election of the data structures is crucial to optimise the execution times. That is why the classroom filters are coded using a dictionary of sets. Once more, we will explain this with an example.

We have a $M$ set of $n$ classroom filters, three groups $G_{1}$, $G_{2}$ and $G_{3}$, and two classrooms $C_{1}$ and $C_{2}$.

\begin{align}
    M &= \{ M_{1}, M_{2}, ..., M_{n} \}\\
    G &= \{ G_{1}, G_{2}, G_{3} \}\\
    C &= \{ C_{1}, C_{2} \}
\end{align}

Then, we define the dictionary as a function $Dict: Keys \rightarrow Values \cup \{ \epsilon \}$ where $\epsilon$ is the $null$ character. That is, $\epsilon \notin Values$.

The keys are represented by the groups, so $Keys \equiv G$. The values depict the different sets of available classrooms for each group. Because the dictionary is as lazy as the LCM, the calculations are performed as needed, so the initial set of values are by default $\epsilon$. Then we can say that $Values = \{ \epsilon, \epsilon, \epsilon \}$.

Accordingly, we have the following cases.

\[
    Dict(x) =
    \begin{cases}
        \epsilon\text{,} &\quad\text{if} x = G_{1}\\
        \epsilon\text{,} &\quad\text{if} x = G_{2}\\
        \epsilon\text{,} &\quad\text{if} x = G_{3}\\
        \epsilon\text{,} &\quad\text{otherwise}
    \end{cases}
\]

We are now in the first execution of the greedy algorithm. Because we start from an empty state and not from an intermediate step, the greedy will try to assign a classroom for all groups. As a result of the values in the dictionary being $null$, the greedy knows that it must execute the filters, updating the dictionary. This is the LFD after the first execution for this case.

\[
    Dict(x) =
    \begin{cases}
        F_{1}\text{,} &\quad\text{if} x = G_{1}\\
        F_{2}\text{,} &\quad\text{if} x = G_{2}\\
        F_{3}\text{,} &\quad\text{if} x = G_{3}\\
        \epsilon\text{,} &\quad\text{otherwise}
    \end{cases}
\]

With each $F_{i} \subset C$ being the filtered classrooms for each group. Example of values for the $F$ sets follow.

\begin{align}
    F_{1} &= \{ C_{1} \}\\
    F_{2} &= \{ C_{1}, C_{2} \}\\
    F_{3} &= \{ \}
\end{align}

We can observe that the for $G_{1}$, classroom $C_{2}$ was filtered out. In the case of $G_{2}$, both classrooms passed al the constraints. And for $G_{3}$, there are no classes available. This is very important, because it implies that with these filters, $G_{3}$ will \textit{always} end up without a classroom. Therefore, a complete solution cannot be found for this case unless the filters are changed.

Lastly, a final remark. We can say that from now on, until the prototype terminates, the greedy will not have to perform the filters for any of the groups again, as the results are already stored in the dictionary. 



\section{Greedy algorithm}

\begin{algorithm}[H]
    \caption{ClassManager Greedy Algorithm}
    \begin{algorithmic}[1]
        \Procedure {GreedyAlgorithm}{assignments}
            \State {$solution\gets copy(assignments)$}
            \State {$repairs\gets \{\}$}
            \State {$solution\gets preprocess(solution)$}
            \For {$\ i \text{ from } 0 \text{ to } length(solution) - 1$}
                \If {$\ !isAssigned(A_{i})$}
                    \State {$c\gets bestClassroomFor(A_{i})$}
                    \If {$\ c \neq \epsilon$}
                        \State {$assignClassroomToGroup(c,\ A_{i},\ solution)$}
                        \State {$assignClassroomToSameGroups(c,\ A_{i},\ solution)$}
                    \Else
                        \State {$addToRepairs(A_{i},\ repairs)$}
                    \EndIf
                \EndIf
            \EndFor
            \State {$solution\gets repair(repairs,\ solution)$}
            \State \textbf{return} $solution$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}


\subsection{Preprocessing}

\begin{algorithm}[H]
    \caption{ClassManager Greedy Algorithm Preprocessing}
    \begin{algorithmic}[1]
        \Procedure {Preprocess}{solution}
            \For {$\ i \text{ from } 0 \text{ to } length(solution) - 1$}
                \If {$\ !isAssigned(A_{i})$}
                    \State {$filtered\gets filterClassroomsFor(group(A_{i}))$}
                    \If {$\ length(filtered) = 1$}
                        \State {$c\gets bestClassroomFor(A_{i})$}
                        \If {$\ c \neq \epsilon$}
                            \State {$assignClassroomToGroup(c,\ A_{i},\ solution)$}
                        \EndIf
                    \EndIf
                \EndIf
            \EndFor
            \State \textbf{return} $solution$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}


\subsection{Heuristic}

\begin{algorithm}[H]
    \caption{ClassManager Greedy Algorithm Assignment Heuristic}
    \begin{algorithmic}[1]
        \Procedure {BestClassroomFor}{$A_{i}$}
            \State {$selected \gets \epsilon$}
            \State {$filtered \gets filterClassroomsFor(group(A_{i}))$}
            \For {$\ j \text{ from } 0 \text{ to } length(filtered) - 1$}
                \State {$selected \gets F_{j}$} \Comment{Filtered classroom $j$}
                \If {$\ !collisionExistsFor(group(A_{i}),\ selected)$}
                    \State {Break out of the filtered classrooms \textit{for loop}}
                \EndIf
                \State {$selected \gets \epsilon$}
            \EndFor
            \State \textbf{return} $selected$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}


\subsection{Repairs}

\begin{algorithm}[H]
    \caption{ClassManager Greedy Algorithm Repairing Process}
    \begin{algorithmic}[1]
        \Procedure {Repair}{repairs, solution}
            \For {$\ i \text{ from } 0 \text{ to } length(repairs) - 1$}
                \State {$filtered \gets filterClassroomsFor(group(A_{i}))$}
                \For {$\ j \text{ from } 0 \text{ to } length(filtered) - 1$}
                    \State {$collisions \gets collisionsFor(group(A_{i}),\ F_{j})$}
                    \If {$\ length(collisions) > 1$}
                        \State {Break out of the filtered classrooms \textit{for loop}} \Comment{Assignment could not be repaired.}
                    \EndIf
                    \State {$group \gets firstElement(collisions)$}
                    \State {$a \gets assignmentFor(group)$}
                    \State {$removeClassroomFromGroup(F_{j},\ a,\ solution)$}
                    \State {$assignClassroomToGroup(F_{j},\ A_{i},\ solution)$}
                    \State {$c \gets bestClassroomFor(a)$}
                    \If {$\ c \neq \epsilon$}
                        \State {$assignClassroomToGroup(c,\ a,\ solution)$} \Comment{Assignment repaired.}
                    \Else
                        \State {$removeClassroomFromGroup(F_{j},\ A_{i},\ solution)$} \Comment{Assignment could not be repaired.}
                        \State {$assignClassroomToGroup(F_{j},\ a,\ solution)$}
                    \EndIf
                \EndFor
            \EndFor
            \State \textbf{return} $solution$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}


\section{Genetic algorithm}

\begin{algorithm}[H]
    \caption{ClassManager Genetic Algorithm (GA)}
    \begin{algorithmic}[1]
        \Procedure {GeneticAlgorithm}{popsize, numgen, maxTime, crossProb, mutProb}
            \State {$best\gets \epsilon$}
            \State {$currentTime\gets \text{get current time}$}
            \State {$gen\gets 0$}
            \State {$P \gets \{ \}$} 
            \For {$\ popsize \text{ times}$}
                \State {$P\gets P \cup \{ \text{new random individual} \}$}
            \EndFor
            \Repeat
                \State {$evaluate(P)$}\Comment{Calculate the fitness of all individuals.}
                \For {$\ \text{each individual } P_{i} \in P$}
                    \If {$\ best = \epsilon \text{ and } Fitness(P_{i}) > Fitness(best)$}
                        \State {$best\gets P_{i}$}
                    \EndIf
                \EndFor
                \State {$Q\gets nextGeneration(P,\ popsize,\ crossProb,\ mutProb)$}
                \State {$P\gets Q$}
                \State {$currentTime\gets \text{update time}$}
                \State {$gen\gets gen + 1$}
            \Until {$\ gen \geq numgen\ \text{ or } currentTime \geq maxTime$}
            \State \textbf{return} $best$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
    \caption{ClassManager Genetic Algorithm Next Generation}
    \begin{algorithmic}[1]
        \Procedure {NextGeneration}{$P$, popsize, crossProb, mutProb}
            \State {$Q\gets \{ \}$}
            \For {$\ popsize / 2 \text{ times}$}
                \State {$\text{Parent } P_{a} \gets selectAndRemove(P)$}
                \State {$\text{Parent } P_{b} \gets selectAndRemove(P)$}
                \State {$\text{Child } C_{a} \gets copy(P_{a})$}
                \State {$\text{Child } C_{b} \gets copy(P_{b})$}
                \If {$\ \text{random number from $0.0$ to $1.0$} > crossProb$}
                    \State {$C_{a} \gets crossover(copy(P_{a}),\ copy(P_{b}))$}
                    \State {$C_{b} \gets crossover(copy(P_{b}),\ copy(P_{a}))$}
                \EndIf
                \If {$\ \text{random number from $0.0$ to $1.0$} > mutProb$}
                    \State {$C_{a} \gets mutation(copy(C_{a}))$}
                    \State {$C_{b} \gets mutation(copy(C_{b}))$}
                \EndIf
                \State {$\text{Winners } W_{a}, W_{b} \gets tournament(P_{a},\ P_{b},\ C_{a},\ C_{b})$}
                \State {$Q\gets Q \cup \{ W_{a}, W_{b} \}$}
            \EndFor
            \State \textbf{return} $Q$
        \EndProcedure
    \end{algorithmic}
\end{algorithm}


\subsection{Fitness function}

\subsection{Operators}

\subsubsection{Selection}

\subsubsection{Crossover}

\subsubsection{Mutation}

\subsubsection{Tournament}

\subsection{Parameters}


